{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KFX05hbAA0qj"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5aAYF0eK_akF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import urllib\n",
    "import json\n",
    "from thesaurus import Word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create complex word to simple word dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['delusion', 'fantasy', 'idea', 'image', 'imagination', 'nightmare', 'thought']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "w = Word(\"dream\")\n",
    "w.synonyms(relevance=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_words():\n",
    "    # with context manager assures us the\n",
    "    # file will be closed when leaving the scope\n",
    "    url = 'https://raw.githubusercontent.com/first20hours/google-10000-english/master/google-10000-english-usa-no-swears.txt'\n",
    "    urllib.request.urlretrieve (url, \"commonwords.txt\")\n",
    "\n",
    "    with open('commonwords.txt',encoding=\"utf8\") as f:\n",
    "        # create a  dictionary object to return\n",
    "        result = dict()\n",
    "        count = 1\n",
    "        for line in f.read().splitlines():\n",
    "            if line not in result:\n",
    "                result[line] = 1\n",
    "            if count > 7999:\n",
    "                break;\n",
    "            count += 1\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_words():\n",
    "    url = \"https://raw.githubusercontent.com/dwyl/english-words/master/words_dictionary.json\"\n",
    "    urllib.request.urlretrieve (url, \"words.json\")\n",
    "    with open('words.json', 'r') as f:\n",
    "        dict = json.load(f)\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_to_simple(simplew, complexw):\n",
    "    file = open(\"lexicaldataset.txt\",\"w\") \n",
    "\n",
    "    # clean/remove all words not exist in thesaurus\n",
    "    # add all complex simple pairs to dataset\n",
    "    \n",
    "    for word in complexw:\n",
    "        if word not in simplew:\n",
    "            try:\n",
    "                for synonym in Word(word).synonyms(relevance=3):\n",
    "                    if synonym in simplew:\n",
    "                        file.write(\"{} . {}\\n\".format(word, synonym))\n",
    "                        break\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    file.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(simple_words[\"surprised\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 370102\n"
     ]
    }
   ],
   "source": [
    "simple_words = get_simple_words()\n",
    "all_words = get_all_words()\n",
    "print(len(simple_words), len(all_words))\n",
    "complex_to_simple(simple_words, all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WCT3eovuAQd0"
   },
   "source": [
    "# Data load and cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pZG7QwyQK0WH"
   },
   "outputs": [],
   "source": [
    "def loadData():\n",
    "\n",
    "  url = 'http://ssli.ee.washington.edu/tial/projects/simplification/aligned-good-0.67.txt'\n",
    "  urllib.request.urlretrieve (url, \"data.txt\")\n",
    "  \n",
    "  simple_field = torchtext.data.Field(sequential=True,include_lengths=True,use_vocab=True,batch_first=True)\n",
    "  complex_field = torchtext.data.Field(sequential=True,include_lengths=True,use_vocab=True,batch_first=True)\n",
    "  \n",
    "  fields = [('complex',complex_field),('simple',simple_field),('closeness',None)]\n",
    "  dataset = torchtext.data.TabularDataset(\"data.txt\",\"tsv\",fields)\n",
    "  \n",
    "  train, valid, text = torchtext.data.Dataset.split(dataset,split_ratio=[0.6,0.2,0.2])\n",
    "  return train, valid, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EGx4knRWPeQk"
   },
   "outputs": [],
   "source": [
    "train, valid, text = loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'table', 'of', 'information', 'is', 'a', 'set', 'of', 'facts', 'arranged', 'in', 'rows', 'and', 'columns', '.']\n",
      "['A', 'table', 'is', 'a', 'means', 'of', 'arranging', 'data', 'in', 'rows', 'and', 'columns', '.']\n",
      "92883 30961 30961\n"
     ]
    }
   ],
   "source": [
    "print(train[0].simple)\n",
    "print(train[0].complex)\n",
    "print(len(train), len(valid), len(text))\n",
    "\n",
    "# for data, label in train:\n",
    "#     print(data, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XWB4AXSN_4IW"
   },
   "source": [
    "# Our Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fYkQWdQZ_hw-"
   },
   "outputs": [],
   "source": [
    "class sentenceSimplifier(nn.Module):\n",
    "    def __init__(self, hidden_size, input_size=113):\n",
    "        super(sentenceSimplifier, self).__init__()\n",
    "       \n",
    "    \n",
    "    def forward(self, x):\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c5lfw0yMANjW"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a8l2H5coAPbs"
   },
   "outputs": [],
   "source": [
    "def train():"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
